# Fingerprint model configuration for robustness testing
# This config defines the frozen model to use for all experiments

model:
  # Model type: "mert", "muq", "openl3", or path to custom model
  type: "mert"
  name: "m-a-p/MERT-v1-330M"  # HuggingFace model identifier
  path: null  # If using custom model, specify path here
  
  # Model checksum for verification (sha256)
  # Update this after freezing the model
  checksum: null
  
  # Device: "cuda", "cpu", or null for auto-detect
  # CRITICAL: GPU acceleration enabled for 5-10x speedup
  device: "cuda"  # Force GPU usage (VPS has GPU)

# Audio processing parameters
audio:
  sample_rate: 44100
  segment_length: 3.5  # seconds (OPTIMIZED: 3.5s for better coverage with minimal latency cost)
  hop_length: null  # null = no overlap, segment_length = hop_length
  mono: true
  normalization: "peak"  # "peak", "rms", or null

# Embedding parameters
embedding:
  dimension: 512  # Expected output dimension
  normalization: "l2"  # "l2", "none"
  dtype: "float32"  # Output embeddings: FP32 (FAISS requirement)
  # Note: Model inference uses FP16 automatically via PyTorch AMP (Automatic Mixed Precision)

# Segment processing
segmentation:
  method: "overlapping"  # Overlapping segments for better coverage (compensation strategy)
  overlap_ratio: 0.1  # 10% overlap (minimal latency cost, better recall)

# Aggregation parameters (for query result fusion)
# OPTIMIZED FOR FP16 AMP + COMPENSATION: 97%+ recall with <550ms latency
aggregation:
  # Similarity threshold: exclude segments with top match similarity below this
  min_similarity_threshold: 0.08  # Lower threshold (compensation for FP16 slight accuracy loss)
  
  # Top-K fusion: use only best-matching segments
  top_k_fusion_ratio: 0.75  # Use top 75% of segments (compensation: better coverage)
  
  # Temporal consistency: weight consecutive segments matching same file
  use_temporal_consistency: true  # ENABLED: Critical for improving recall (especially for difficult transforms)
  
  # Aggregation weights (must sum to ~1.0, will be normalized)
  # Optimized for recall compensation while maintaining similarity
  weights:
    similarity: 0.55      # Slightly reduced (was 0.60) - compensation strategy
    rank_1: 0.28          # Increased (was 0.25) - stronger signal for recall
    rank_5: 0.12          # Increased (was 0.10) - supporting signal
    match_ratio: 0.05     # Same
    temporal: 0.0         # Temporal weight handled separately in temporal_score
  
  # Confidence-based re-ranking
  use_confidence_rerank: true  # ENABLED: Improves similarity scores significantly
  min_confidence_threshold: 0.0  # Minimum confidence to include result (0.0-1.0, 0.0 = no filtering)
  
  # Second-stage re-ranking (more thorough analysis of top candidates)
  second_stage_rerank:
    enabled: true  # ENABLED: More thorough re-ranking (compensation strategy)
    top_k: 5  # Increased from 3 (more thorough re-ranking for better accuracy)
  
  # Result validation and quality checks
  validation:
    enabled: false  # Disabled for speed (confidence rerank provides similar benefit)
    min_quality_score: 0.0  # Minimum quality score to consider valid (0.0-1.0)
  
  # Adaptive threshold: dynamically adjust similarity threshold based on query quality
  use_adaptive_threshold: false  # Disabled (fixed threshold works well with GPU)
  adaptive_threshold_base: 0.1  # Base threshold (not used when disabled)
  adaptive_threshold_sensitivity: 0.1  # Sensitivity (not used when disabled)

# Multi-scale feature fusion (use multiple segment lengths for better recall)
multi_scale:
  enabled: false  # Set to true to enable multi-scale fusion (increases latency ~2-3x)
  segment_lengths:
    - 0.75  # Shorter segments for fine-grained matching
    - 1.0   # Primary segment length
    - 1.5   # Longer segments for stable matching
  weights:
    - 0.25  # Weight for shortest length
    - 0.50  # Weight for primary length
    - 0.25  # Weight for longest length

# Metadata
metadata:
  version: "v1"
  created_date: null  # Set when model is frozen
  description: "MERT-based fingerprint model for audio identification"
