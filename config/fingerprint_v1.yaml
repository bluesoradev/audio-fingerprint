# Fingerprint model configuration for robustness testing
# This config defines the frozen model to use for all experiments

model:
  # Model type: "mert", "muq", "openl3", or path to custom model
  type: "mert"
  name: "m-a-p/MERT-v1-330M"  # HuggingFace model identifier
  path: null  # If using custom model, specify path here
  
  # Model checksum for verification (sha256)
  # Update this after freezing the model
  checksum: null
  
  # Device: "cuda", "cpu", or null for auto-detect
  # CRITICAL: GPU acceleration enabled for 5-10x speedup
  device: "cuda"  # Force GPU usage (VPS has GPU)

# Audio processing parameters
audio:
  sample_rate: 44100
  segment_length: 4.0  # seconds (OPTIMIZED FOR LATENCY: 4.0s dramatically reduces segments for <550ms target)
  hop_length: null  # null = no overlap, segment_length = hop_length
  mono: true
  normalization: "peak"  # "peak", "rms", or null

# Embedding parameters
embedding:
  dimension: 512  # Expected output dimension
  normalization: "l2"  # "l2", "none"
  dtype: "float16"  # FP16 for 2x GPU speedup (minimal accuracy loss, critical for <550ms latency)

# Segment processing
segmentation:
  method: "fixed_length"  # Fixed length (no overlap) for maximum speed
  overlap_ratio: 0.0  # No overlap for faster processing (minimal impact on recall with 2.5s segments)

# Aggregation parameters (for query result fusion)
# OPTIMIZED FOR GPU: Balanced settings for 97%+ recall and high similarity with <550ms latency
aggregation:
  # Similarity threshold: exclude segments with top match similarity below this
  min_similarity_threshold: 0.1  # Lower threshold to include more good matches (improves recall)
  
  # Top-K fusion: use only best-matching segments
  top_k_fusion_ratio: 0.6  # Use top 60% of segments (optimized for speed while maintaining recall)
  
  # Temporal consistency: weight consecutive segments matching same file
  use_temporal_consistency: true  # ENABLED: Critical for improving recall (especially for difficult transforms)
  
  # Aggregation weights (must sum to ~1.0, will be normalized)
  # Optimized for high similarity scores while maintaining recall
  weights:
    similarity: 0.60      # Increased to emphasize similarity score (improves similarity metric)
    rank_1: 0.25          # Strong signal for recall
    rank_5: 0.10          # Supporting signal
    match_ratio: 0.05     # Minimal weight
    temporal: 0.0         # Temporal weight handled separately in temporal_score
  
  # Confidence-based re-ranking
  use_confidence_rerank: true  # ENABLED: Improves similarity scores significantly
  min_confidence_threshold: 0.0  # Minimum confidence to include result (0.0-1.0, 0.0 = no filtering)
  
  # Second-stage re-ranking (more thorough analysis of top candidates)
  second_stage_rerank:
    enabled: false  # DISABLED for maximum speed (confidence rerank provides sufficient benefit)
    top_k: 3  # Only re-rank top 3 (not used when disabled)
  
  # Result validation and quality checks
  validation:
    enabled: false  # Disabled for speed (confidence rerank provides similar benefit)
    min_quality_score: 0.0  # Minimum quality score to consider valid (0.0-1.0)
  
  # Adaptive threshold: dynamically adjust similarity threshold based on query quality
  use_adaptive_threshold: false  # Disabled (fixed threshold works well with GPU)
  adaptive_threshold_base: 0.1  # Base threshold (not used when disabled)
  adaptive_threshold_sensitivity: 0.1  # Sensitivity (not used when disabled)

# Multi-scale feature fusion (use multiple segment lengths for better recall)
multi_scale:
  enabled: false  # Set to true to enable multi-scale fusion (increases latency ~2-3x)
  segment_lengths:
    - 0.75  # Shorter segments for fine-grained matching
    - 1.0   # Primary segment length
    - 1.5   # Longer segments for stable matching
  weights:
    - 0.25  # Weight for shortest length
    - 0.50  # Weight for primary length
    - 0.25  # Weight for longest length

# Metadata
metadata:
  version: "v1"
  created_date: null  # Set when model is frozen
  description: "MERT-based fingerprint model for audio identification"
